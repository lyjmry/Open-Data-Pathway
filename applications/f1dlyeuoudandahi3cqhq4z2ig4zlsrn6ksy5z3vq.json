{
  "Version": "1.3",
  "ID": "f1dlyeuoudandahi3cqhq4z2ig4zlsrn6ksy5z3vq",
  "Issue Number": "17",
  "Client Contract Address": "f410f2xgqfmpd53zdbfy36etp5lduum56cvxm4ziraty",
  "Client": {
    "Name": "USCB& NARA&CELLxGENE",
    "Region": "United States",
    "Industry": "Life Science / Healthcare",
    "Website": "https://www.archives.gov/developer/1940-census",
    "Social Media": "public.dataset.program@nara.gov",
    "Social Media Type": "Other",
    "Role": "Data Preparer"
  },
  "Project": {
    "Brief history of your project and organization": "D&D Tech is a technology company based in Hong Kong. We specialize in data storage, data encryption. Is a participant and builder of Filecoin and IPFS.",
    "Is this project associated with other projects/ecosystem stakeholders?": "No",
    "Describe the data being stored onto Filecoin": "The 1940 Census population schedules were created by the Bureau of the Census in an attempt to enumerate every person living in the United States on April 1, 1940, although some persons were missed. The 1940 census population schedules were digitized by the National Archives and Records Administration (NARA) and released publicly on April 2, 2012.\nThe 1950 Census population schedules were created by the Bureau of the Census in an attempt to enumerate every person living in the United States on April 1, 1950, although some persons were missed. The 1950 census population schedules were digitized by the National Archives and Records Administration (NARA) and released publicly on April 1, 2022.",
    "Where was the data currently stored in this dataset sourced from": "AWS Cloud",
    "How do you plan to prepare the dataset": "We used the Go language to develop a set of tools that automatically download, cut, package data, and place orders. The tool will download the data set file from AWS, package the data set into a car file of the corresponding size by setting parameters such as sector size, and then distribute the car file to each SP through bandwidth and hard disk mail. Then, we use Boost to issue orders offline to let the SP start packaging using the Lotus program.",
    "Please share a sample of the data (a link to a file, an image, a table, etc., are good ways to do this.)": "aws s3 ls --no-sign-request s3://cellxgene-census-public-us-west-2/  29.8 TiB\naws s3 ls --no-sign-request s3://uscb-2020-product-releases/decennial/dhc/2010/ 23.8 TiB\naws s3 ls --no-sign-request s3://uscb-2020-product-releases/decennial/dhc/2020/nmf/2020-dhc-nmf/ 22.0 TiB\naws s3 ls --no-sign-request s3://nara-1940-census/ 15.1 TiB\naws s3 ls --no-sign-request s3://nara-1950-census/ 188.7 TiB",
    "Confirm that this is a public dataset that can be retrieved by anyone on the network (i.e., no specific permissions or access rights are required to view the data)": "[x] I confirm",
    "What is the expected retrieval frequency for this data": "Yearly",
    "For how long do you plan to keep this dataset stored on Filecoin": "1.5 to 2 years",
    "In which geographies do you plan on making storage deals": "Asia other than Greater China, North America, South America, Europe",
    "How will you be distributing your data to storage providers": "HTTP or FTP server, IPFS, Shipping hard drives",
    "Please list the provider IDs and location of the storage providers you will be working with. Note that it is a requirement to list a minimum of 5 unique provider IDs, and that your client address will be verified against this list in the future": "f03649204 HongKong\nf03649212 HongKong\nf03649217 Singapore\nf03649227 Singapore\nf03637821 Germany",
    "Can you confirm that you will follow the Fil+ guideline (Data owner should engage at least 4 SPs and no single SP ID should receive >30% of a client's allocated DataCap)": "Yes"
  },
  "Datacap": {
    "Type": "ldn-v3",
    "Data Type": "Slingshot",
    "Total Requested Amount": "3.2PiB",
    "Single Size Dataset": "400TiB",
    "Replicas": 8,
    "Weekly Allocation": "2PiB"
  },
  "Lifecycle": {
    "State": "Granted",
    "Validated At": "2025-10-29 04:24:12.347203150 UTC",
    "Validated By": "lyjmry",
    "Active": true,
    "Updated At": "2025-10-29 04:24:12.347198048 UTC",
    "Active Request ID": "dd92afe3-ab72-4077-a5da-773bb3a1c941",
    "On Chain Address": "f1dlyeuoudandahi3cqhq4z2ig4zlsrn6ksy5z3vq",
    "Multisig Address": "false",
    "edited": false
  },
  "Allocation Requests": [
    {
      "ID": "dd92afe3-ab72-4077-a5da-773bb3a1c941",
      "Request Type": "First",
      "Created At": "2025-10-29 04:16:10.781702738 UTC",
      "Updated At": "2025-10-29 04:16:10.781703672 UTC",
      "Active": false,
      "Allocation Amount": "281474976710656 B",
      "Amount of Datacap Sent to Contract": "281474976710656 B",
      "Signers": [
        {
          "Github Username": "lyjmry",
          "Signing Address": "f1cdaymbuyum3yf26ibsushykd6imktbp2cuzcnmi",
          "Created At": "2025-10-29 04:24:09.436000000 UTC",
          "Message CID": "bafy2bzacecaptkqva7hoahk4gbtk77toickervt2skfr4avhjmaapnmcx2gfa",
          "Increase allowance CID": "bafy2bzacec4kz64bmyw3a37itexjl53acafeio74pssz6hlio23rdhmwdgekq"
        }
      ]
    }
  ],
  "Storage Providers Change Requests": [
    {
      "ID": "95da9394-d573-4cf0-b2f7-fbd9db3a86cb",
      "Created At": "2025-10-29 04:20:37.890562736 UTC",
      "Updated At": "2025-10-29 04:20:37.890569180 UTC",
      "Active": false,
      "Allowed Storage Providers": [
        3649204,
        3649212,
        3649217,
        3649227,
        3637821
      ],
      "Max Deviation": "10%",
      "Signers": [
        {
          "Github Username": "lyjmry",
          "Signing Address": "f1cdaymbuyum3yf26ibsushykd6imktbp2cuzcnmi",
          "Set Max Deviation CID": "bafy2bzacedsx27xiunlaixahacoohdcvimxl7t6xfbyynlxdloqaath2k5plw",
          "Add Allowed Storage Providers CID": {
            "bafy2bzacebbewevsr546og72bxmxostpmwocalkcankjzve7t7nboer45jzmi": [
              "3649204",
              "3649212",
              "3649217",
              "3649227",
              "3637821"
            ]
          }
        }
      ]
    }
  ]
}